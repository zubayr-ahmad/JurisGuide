{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation is using LangGraph to implement the chatting system\n",
    "import sqlite3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List, Annotated, Dict, Any\n",
    "from langgraph.graph import StateGraph, END\n",
    "import uuid\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Database and Vector Store paths\n",
    "DB_PATH = os.getenv(\"DB_PATH\", \"data/chat_history.db\")\n",
    "VECTOR_STORE_PATH = os.getenv(\"VECTOR_STORE_PATH\", \"data/chroma_db\")\n",
    "PROCESSED_FOLDER = \"data/processed\"\n",
    "LLM_API_KEY = os.getenv(\"LLM_API_KEY\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\")\n",
    "HISTORY_CONTEXT = 5\n",
    "RETRIEVE_DOCS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Layer\n",
    "class ChatDatabase:\n",
    "    def __init__(self):\n",
    "        self.conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
    "        self._create_table()\n",
    "\n",
    "    def _create_table(self):\n",
    "        # print(\"Creating tables >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS chats (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                session_id TEXT,\n",
    "                user_message TEXT,\n",
    "                response TEXT,\n",
    "                reference_docs TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS sessions (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                session_id TEXT,\n",
    "                name TEXT,\n",
    "                created_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    def save_chat(self, session_id: str, user_message: str, response: str, reference_docs=None):\n",
    "        \"\"\"Save a chat message with references stored as JSON\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        \n",
    "        # Convert list of Documents to list of dictionaries\n",
    "        references = json.dumps([\n",
    "            {\"page_content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "            for doc in (reference_docs or [])\n",
    "        ])\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO chats (session_id, user_message, response, reference_docs)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        \"\"\", (session_id, user_message, response, references))\n",
    "        \n",
    "        self.conn.commit()\n",
    "    def create_session(self, session_id: str, metadata: dict):\n",
    "        \"\"\"Create a new session with metadata\"\"\"\n",
    "        # Add this method to save session metadata (name, created_at) to your database\n",
    "        # Implementation depends on your database structure\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO sessions (session_id, name, created_at)\n",
    "            VALUES (?, ?, ?)\n",
    "        \"\"\", (session_id, metadata['name'], metadata['created_at']))\n",
    "        self.conn.commit()\n",
    "\n",
    "    def get_all_sessions(self):\n",
    "        \"\"\"Retrieve all sessions with their metadata\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT session_id, name, created_at\n",
    "            FROM sessions\n",
    "        \"\"\")\n",
    "        sessions = {}\n",
    "        for row in cursor.fetchall():\n",
    "            sessions[row[0]] = {\n",
    "                'name': row[1],\n",
    "                'created_at': row[2]\n",
    "            }\n",
    "        return sessions\n",
    "\n",
    "    def get_chat_history(self, session_id: str, limit=HISTORY_CONTEXT):\n",
    "        \"\"\"Retrieve chat history for a session with reference docs as list of dicts\"\"\"\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT user_message, response, reference_docs\n",
    "            FROM chats\n",
    "            WHERE session_id = ?\n",
    "            ORDER BY timestamp DESC LIMIT ?\n",
    "        \"\"\", (session_id, limit))\n",
    "        \n",
    "        history = []\n",
    "        for row in cursor.fetchall():\n",
    "            user_message, response, reference_docs_json = row\n",
    "            reference_docs = json.loads(reference_docs_json) if reference_docs_json else []\n",
    "            \n",
    "            history.append({\n",
    "                'user_message': user_message,\n",
    "                'response': response,\n",
    "                'reference_docs': reference_docs\n",
    "            })\n",
    "        \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Retrieval Layer\n",
    "class DocumentRetriever:\n",
    "    def __init__(self):\n",
    "        self.embeddings = HuggingFaceEmbeddings()\n",
    "        self.processed_files_path = os.path.join(VECTOR_STORE_PATH, \"processed_files.json\")\n",
    "        self.processed_files = self._load_processed_files()\n",
    "        self.db = self._initialize_vectorstore()\n",
    "\n",
    "    def _load_processed_files(self) -> Dict[str, Dict]:\n",
    "        \"\"\"Load the list of processed files and their metadata.\"\"\"\n",
    "        if os.path.exists(self.processed_files_path):\n",
    "            with open(self.processed_files_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {}\n",
    "\n",
    "    def _save_processed_files(self):\n",
    "        \"\"\"Save the list of processed files and their metadata.\"\"\"\n",
    "        os.makedirs(VECTOR_STORE_PATH, exist_ok=True)\n",
    "        with open(self.processed_files_path, 'w') as f:\n",
    "            json.dump(self.processed_files, f, indent=2)\n",
    "\n",
    "    def _get_file_metadata(self, filepath: str) -> Dict:\n",
    "        \"\"\"Get file metadata including modification time and size.\"\"\"\n",
    "        stat = os.stat(filepath)\n",
    "        return {\n",
    "            \"mtime\": stat.st_mtime,\n",
    "            \"size\": stat.st_size\n",
    "        }\n",
    "\n",
    "    def _has_file_changed(self, filepath: str) -> bool:\n",
    "        \"\"\"Check if a file has been modified since last processing.\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            return False\n",
    "\n",
    "        current_metadata = self._get_file_metadata(filepath)\n",
    "        filename = os.path.basename(filepath)\n",
    "\n",
    "        if filename not in self.processed_files:\n",
    "            return True\n",
    "\n",
    "        stored_metadata = self.processed_files[filename]\n",
    "        return (current_metadata[\"mtime\"] != stored_metadata[\"mtime\"] or\n",
    "                current_metadata[\"size\"] != stored_metadata[\"size\"])\n",
    "\n",
    "    def _initialize_vectorstore(self):\n",
    "        \"\"\"Initialize or update the vector store with new or modified documents.\"\"\"\n",
    "        if not os.path.exists(PROCESSED_FOLDER):\n",
    "            os.makedirs(PROCESSED_FOLDER)\n",
    "\n",
    "        # Get all PDF files in the processed folder\n",
    "        pdf_files = [f for f in os.listdir(PROCESSED_FOLDER) if f.endswith(\".pdf\")]\n",
    "        \n",
    "        # Check for new or modified files\n",
    "        new_docs = []\n",
    "        for filename in pdf_files:\n",
    "            filepath = os.path.join(PROCESSED_FOLDER, filename)\n",
    "            \n",
    "            if self._has_file_changed(filepath):\n",
    "                print(f\"Processing new/modified file: {filename}\")\n",
    "                loader = PyPDFLoader(filepath)\n",
    "                new_docs.extend(loader.load())\n",
    "                \n",
    "                # Update processed files record\n",
    "                self.processed_files[filename] = self._get_file_metadata(filepath)\n",
    "        \n",
    "        # Save the updated processed files record\n",
    "        self._save_processed_files()\n",
    "\n",
    "        # If we have new documents, process them and update the vector store\n",
    "        if new_docs:\n",
    "            print(f\"Number of new documents to process: {len(new_docs)}\")\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)\n",
    "            texts = text_splitter.split_documents(new_docs)\n",
    "            print(f\"Created {len(texts)} chunks from new documents\")\n",
    "            \n",
    "            # If vector store exists, add to it; otherwise create new\n",
    "            if os.path.exists(VECTOR_STORE_PATH):\n",
    "                db = Chroma(persist_directory=VECTOR_STORE_PATH, \n",
    "                          embedding_function=self.embeddings)\n",
    "                db.add_documents(texts)\n",
    "                return db\n",
    "            else:\n",
    "                return Chroma.from_documents(texts, self.embeddings, \n",
    "                                          persist_directory=VECTOR_STORE_PATH)\n",
    "        \n",
    "        # If no new documents, just load existing vector store\n",
    "        return Chroma(persist_directory=VECTOR_STORE_PATH, \n",
    "                     embedding_function=self.embeddings)\n",
    "\n",
    "    def retrieve_documents(self, query: str, k=RETRIEVE_DOCS) -> List[Any]:\n",
    "        \"\"\"Retrieve similar documents for a given query.\"\"\"\n",
    "        return self.db.similarity_search(query, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Response Generation\n",
    "class ResponseGenerator:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGroq(api_key=LLM_API_KEY, \n",
    "                          model=LLM_MODEL)\n",
    "\n",
    "    def generate_response(self, context: str, history: str, query: str) -> str:\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are an AI assistant. Use the provided context to generate accurate answers. If the context is insufficient, state that you are unsure rather than guessing.\"),\n",
    "            HumanMessage(content=f\"Context:\\n{context}\\n\\nConversation History:\\n{history}\\n\\nUser Query:\\n{query}\\n\\nResponse:\")\n",
    "        ]\n",
    "\n",
    "        return self.llm(messages).content\n",
    "    \n",
    "    def custom_call(self, user_prompt, system_prompt=None):\n",
    "        messages = [HumanMessage(content=user_prompt)]\n",
    "        if system_prompt:\n",
    "            messages.insert(0, SystemMessage(system_prompt))\n",
    "        return self.llm(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph State Definition\n",
    "class ChatState(TypedDict):\n",
    "    session_id: str\n",
    "    user_message: str\n",
    "    reference_docs: List[Any]\n",
    "    response: str\n",
    "    requires_retrieval: bool\n",
    "    history: Annotated[List[Dict[str, str]], lambda x, y: x + y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph Nodes\n",
    "class ChatNodes:\n",
    "    def __init__(self):\n",
    "        self.db = ChatDatabase()\n",
    "        self.retriever = DocumentRetriever()\n",
    "        self.generator = ResponseGenerator()\n",
    "\n",
    "    def retrieve_documents(self, state: ChatState) -> Dict:\n",
    "        docs = self.retriever.retrieve_documents(state[\"user_message\"])\n",
    "        return {\"reference_docs\": docs}\n",
    "\n",
    "    def generate_response(self, state: ChatState) -> Dict:\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in state[\"reference_docs\"]])\n",
    "        history = \"\\n\".join([f\"User: {msg['user_message']}\\nBot: {msg['response']}\" \n",
    "                           for msg in state.get(\"history\", [])[-HISTORY_CONTEXT:]])\n",
    "        print(\"Context >>>>>>>>>>>>>>>>>>>>>>>>\", context)\n",
    "        print(\"History >>>>>>>>>>>>>>>>>>>>>>>>\", history)\n",
    "        response = self.generator.generate_response(\n",
    "            context=context,\n",
    "            history=history,\n",
    "            query=state[\"user_message\"]\n",
    "        )\n",
    "        return {\"response\": response}\n",
    "\n",
    "    def save_conversation(self, state: ChatState) -> Dict:\n",
    "        self.db.save_chat(\n",
    "            state[\"session_id\"],\n",
    "            state[\"user_message\"],\n",
    "            state[\"response\"],\n",
    "            reference_docs=state[\"reference_docs\"]\n",
    "        )\n",
    "        return {\n",
    "            \"history\": [{\n",
    "                \"user_message\": state[\"user_message\"],\n",
    "                \"response\": state[\"response\"],\n",
    "                \"reference_docs\": state[\"reference_docs\"]\n",
    "            }]\n",
    "        }\n",
    "    \n",
    "    def decide_retrieval(self, state: ChatState):\n",
    "        \"\"\"Uses the LLM to decide whether retrieval is needed.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant that determines whether a user's query requires retrieving external knowledge.\n",
    "\n",
    "        If the query is a greeting or a general conversational question (like \"How are you?\"), respond `False`.\n",
    "        If the query asks about specific knowledge (like documentation, facts, or other stored data), respond `True`.\n",
    "\n",
    "        Query: \"{state['user_message']}\"\n",
    "        Answer with 'True' if retrieval is needed, otherwise 'False'. It should be either of them in all cases\n",
    "        \"\"\"\n",
    "\n",
    "        response = self.generator.custom_call(prompt)  \n",
    "        print(\"Response from decider >>>>>>>>>>>>>>>>>>>>>>>>\", response)\n",
    "        state['requires_retrieval'] = \"true\" in response.lower().strip() \n",
    "        print(\"State\", state)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph Workflow Setup with LLM Classification\n",
    "def create_workflow():\n",
    "    nodes = ChatNodes()\n",
    "    workflow = StateGraph(ChatState)\n",
    "\n",
    "    workflow.add_node(\"decide_retrieval\", nodes.decide_retrieval)  # LLM decides if retrieval is needed\n",
    "    workflow.add_node(\"retrieve\", nodes.retrieve_documents)\n",
    "    workflow.add_node(\"generate\", nodes.generate_response)\n",
    "    workflow.add_node(\"save\", nodes.save_conversation)\n",
    "\n",
    "    workflow.set_entry_point(\"decide_retrieval\")\n",
    "\n",
    "    # Conditional transition based on LLM decision\n",
    "    workflow.add_conditional_edges(\n",
    "        \"decide_retrieval\",\n",
    "        lambda state: \"retrieve\" if state['requires_retrieval'] else \"generate\",\n",
    "        {\"retrieve\": \"retrieve\", \"generate\": \"generate\"},\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", \"save\")\n",
    "    workflow.add_edge(\"save\", END)\n",
    "\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangGraphChat:\n",
    "    def __init__(self):\n",
    "        self.workflow = create_workflow()\n",
    "        self.db = ChatDatabase()\n",
    "\n",
    "    def chat(self, user_message: str, session_id: str = None) -> Dict:\n",
    "        session_id = session_id or str(uuid.uuid4())\n",
    "        history = self.db.get_chat_history(session_id, limit=HISTORY_CONTEXT)\n",
    "        # print(\"History >>>>>>>>>>>>>>>\", history)\n",
    "        # print(\"Session id >>>>>>>>>>>>>>>>>>>>>>>\", session_id)\n",
    "        initial_state = {\n",
    "            \"session_id\": session_id,\n",
    "            \"user_message\": user_message,\n",
    "            \"reference_docs\": [],\n",
    "            \"response\": \"\",\n",
    "            \"history\": [{\"user_message\": h['user_message'], \"response\": h[\"response\"], \"reference_docs\":h['reference_docs']} for h in history]\n",
    "        }\n",
    "\n",
    "        result = self.workflow.invoke(initial_state)\n",
    "        return {\n",
    "            \"session_id\": session_id,\n",
    "            \"response\": result[\"response\"],\n",
    "            \"reference_docs\": [{\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata\n",
    "            } for doc in result[\"reference_docs\"]]\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from decider >>>>>>>>>>>>>>>>>>>>>>>> False\n",
      "State {'session_id': 'eba06b0d-5952-4516-98af-d085c9f960c8', 'user_message': 'Hello', 'reference_docs': [], 'response': '', 'history': [], 'requires_retrieval': False}\n",
      "Context >>>>>>>>>>>>>>>>>>>>>>>> \n",
      "History >>>>>>>>>>>>>>>>>>>>>>>> \n"
     ]
    }
   ],
   "source": [
    "chatbot = LangGraphChat()\n",
    "result = chatbot.chat(\"Hello\")\n",
    "print(f\"Response: {result['response']}\")\n",
    "print(f\"Session ID: {result['session_id']}\")\n",
    "print(f\"References: {result['reference_docs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_id': 'eba06b0d-5952-4516-98af-d085c9f960c8',\n",
       " 'response': 'Hello, how can I assist you today?',\n",
       " 'reference_docs': []}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a3949cea-bfaf-4150-9acb-ffc2b1c522d0\n",
    "response = chatbot.chat(\"Can you elaborate on point 3?\", session_id=\"a3949cea-bfaf-4150-9acb-ffc2b1c522d0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_id': 'a3949cea-bfaf-4150-9acb-ffc2b1c522d0',\n",
       " 'response': \"Based on the provided context, point 3 states that where a Certificate of Entitlement has been granted to the Official Participant in respect of imports and supplies covered by Paragraphs (a) and (b) of Clause 1 of Article 2 of this Decision, the Official Participant is required to inform the Bureau.\\n\\nTo elaborate, the Certificate of Entitlement is a document issued by the Authority in response to the request made by the Bureau Expo 2020 Dubai. The Certificate serves as evidence of the entitlement to the refund, and it is typically prepared by the Authority after verifying the refund claim and meeting the agreed-upon requirements.\\n\\nThe Certificate of Entitlement would likely include information such as:\\n\\n- The name of the Official Participant\\n- The amount of the refund\\n- Any other relevant details\\n\\nThe Bureau Expo 2020 Dubai would then use this Certificate to support their request for a refund to the Authority. It's worth noting that the specific requirements for the Certificate of Entitlement are not explicitly stated in the provided context, but it is likely that the Authority would require the Bureau Expo 2020 Dubai to provide documentation or evidence to support the refund claim, and the Certificate would be a formal acknowledgment of the entitlement to the refund.\\n\\nIn this context, the Bureau Expo 2020 Dubai would be required to provide information to the Bureau regarding the Certificate of Entitlement, but the specific requirements for this information are not explicitly stated in the provided context.\",\n",
       " 'references': [{'content': 'respect of any space or presentation.  \\n4. Where a Certificate of Entitlement has been granted to the Official Participant in \\nrespect of imports and supplies covered by Paragraphs (a) and (b) of Clause 1 of \\nArticle 2 of this Decision, the Official Participant is required to inform the Bureau',\n",
       "   'metadata': {'page': 3,\n",
       "    'page_label': '4',\n",
       "    'source': 'data/processed\\\\279926_cabinet_decision_1_2020__refund_of_vat_paid_on_goods_and_services_connected_with_expo_2020.pdf'}},\n",
       "  {'content': 'respect of any space or presentation.  \\n4. Where a Certificate of Entitlement has been granted to the Official Participant in \\nrespect of imports and supplies covered by Paragraphs (a) and (b) of Clause 1 of \\nArticle 2 of this Decision, the Official Participant is required to inform the Bureau',\n",
       "   'metadata': {'page': 3,\n",
       "    'page_label': '4',\n",
       "    'source': 'data/processed\\\\279926_cabinet_decision_1_2020__refund_of_vat_paid_on_goods_and_services_connected_with_expo_2020.pdf'}},\n",
       "  {'content': 'respect of any space or presentation.  \\n4. Where a Certificate of Entitlement has been granted to the Official Participant in \\nrespect of imports and supplies covered by Paragraphs (a) and (b) of Clause 1 of \\nArticle 2 of this Decision, the Official Participant is required to inform the Bureau',\n",
       "   'metadata': {'page': 3,\n",
       "    'page_label': '4',\n",
       "    'source': 'data/processed\\\\279926_cabinet_decision_1_2020__refund_of_vat_paid_on_goods_and_services_connected_with_expo_2020.pdf'}}]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = chatbot.db.get_chat_history(\"a3949cea-bfaf-4150-9acb-ffc2b1c522d0\", limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What is the refund policy?',\n",
       "  'Based on the provided context, the refund policy involves the following steps:\\n\\n1. The Bureau Expo 2020 Dubai makes a request to the Authority to refund the amount, provided the refund claim is correct.\\n2. The Authority and Bureau Expo 2020 Dubai agree on procedural, evidential, and verification requirements to be met by the Office of the Official Participant or any other Person to be eligible for the refund claim (Article 4: Requirements for Refund).\\n3. Where the refund claim is correct, the Bureau Expo 2020 Dubai makes a request to the Authority to refund the amount, and the Authority prepares a Certificate on Entitlement (Article 5: Certificate on Entitlement).\\n\\nTherefore, the refund policy is that the Bureau Expo 2020 Dubai requests the Authority for a refund if the claim is correct, after meeting the agreed-upon requirements and obtaining the Certificate on Entitlement from the Authority.'),\n",
       " ('Can you elaborate on point 3?',\n",
       "  \"Based on the provided context, point 3 states that where the refund claim is correct, the Bureau Expo 2020 Dubai makes a request to the Authority to refund the amount, and the Authority prepares a Certificate on Entitlement.\\n\\nTo elaborate, the Certificate on Entitlement is a document issued by the Authority in response to the request made by the Bureau Expo 2020 Dubai. The Certificate serves as evidence of the entitlement to the refund, and it is typically prepared by the Authority after verifying the refund claim and meeting the agreed-upon requirements.\\n\\nThe Certificate on Entitlement would likely include information such as the name of the Official Participant, the amount of the refund, and any other relevant details. The Bureau Expo 2020 Dubai would then use this Certificate to support their request for a refund to the Authority.\\n\\nIt's worth noting that the specific requirements for the Certificate on Entitlement are not explicitly stated in the provided context, but it is likely that the Authority would require the Bureau Expo 2020 Dubai to provide documentation or evidence to support the refund claim, and the Certificate would be a formal acknowledgment of the entitlement to the refund.\"),\n",
       " ('Can you elaborate on point 3?',\n",
       "  \"Based on the provided context, point 3 states that where the refund claim is correct, the Bureau Expo 2020 Dubai makes a request to the Authority to refund the amount, and the Authority prepares a Certificate on Entitlement.\\n\\nTo elaborate, the Certificate on Entitlement is a document issued by the Authority in response to the request made by the Bureau Expo 2020 Dubai. The Certificate serves as evidence of the entitlement to the refund, and it is typically prepared by the Authority after verifying the refund claim and meeting the agreed-upon requirements.\\n\\nThe Certificate on Entitlement would likely include information such as:\\n\\n- The name of the Official Participant\\n- The amount of the refund\\n- Any other relevant details\\n\\nThe Bureau Expo 2020 Dubai would then use this Certificate to support their request for a refund to the Authority. It's worth noting that the specific requirements for the Certificate on Entitlement are not explicitly stated in the provided context, but it is likely that the Authority would require the Bureau Expo 2020 Dubai to provide documentation or evidence to support the refund claim, and the Certificate would be a formal acknowledgment of the entitlement to the refund.\"),\n",
       " ('Can you elaborate on point 3?',\n",
       "  \"Based on the provided context, point 3 states that where a Certificate of Entitlement has been granted to the Official Participant in respect of imports and supplies covered by Paragraphs (a) and (b) of Clause 1 of Article 2 of this Decision, the Official Participant is required to inform the Bureau.\\n\\nTo elaborate, the Certificate of Entitlement is a document issued by the Authority in response to the request made by the Bureau Expo 2020 Dubai. The Certificate serves as evidence of the entitlement to the refund, and it is typically prepared by the Authority after verifying the refund claim and meeting the agreed-upon requirements.\\n\\nThe Certificate of Entitlement would likely include information such as:\\n\\n- The name of the Official Participant\\n- The amount of the refund\\n- Any other relevant details\\n\\nThe Bureau Expo 2020 Dubai would then use this Certificate to support their request for a refund to the Authority. It's worth noting that the specific requirements for the Certificate of Entitlement are not explicitly stated in the provided context, but it is likely that the Authority would require the Bureau Expo 2020 Dubai to provide documentation or evidence to support the refund claim, and the Certificate would be a formal acknowledgment of the entitlement to the refund.\\n\\nIn this context, the Bureau Expo 2020 Dubai would be required to provide information to the Bureau regarding the Certificate of Entitlement, but the specific requirements for this information are not explicitly stated in the provided context.\")]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
